# -*- coding: utf-8 -*-
"""Machine_learning_Group8_Assignment_2 (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OL_hL3EKAdhcrzyvL2gx-ptF7XUB624N

#Group 8 Assignment 2

#Problem 1 Implementation of Navie Baysien Classifier:

## **Import important libraries**
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np #to deal with arrays
import pandas as pd #to deal with dataframes
import matplotlib.pyplot as plt #pyplot is a collection of command style functions that make matplotlib work like MATLAB
import seaborn as sns #for visualization
from sklearn.datasets import load_wine #load the dataset
# %matplotlib inline

"""## **Load the dataset**"""

#load the dataset
data = load_wine()

df = pd.DataFrame(data.data,columns=data.feature_names)

#print the head of the data
df.head()

#descibe the data
df.describe()

#get some information about the data
df.info()

target = pd.Series(data.target)

target.value_counts()

df = pd.concat([df,target],axis= 1)

df.head()

#to view the corelations between the attribues
sns.pairplot(df,hue = 0)

"""## **a- Split the dataset into train and test dataset**"""

from sklearn.model_selection import train_test_split
x_train ,x_test, y_train , y_test = train_test_split(df.drop(0,axis = 1),df[0],test_size = 0.2 ,random_state=42)

#print the x_train data
x_train

"""**Implement GaussianNB classifier**

Gaussian Naive Bayes is a variant of Naive Bayes that follows Gaussian normal distribution and supports continuous data.
"""

from sklearn.naive_bayes import GaussianNB #to import GaussianNB classifier library
nb = GaussianNB()
nb.fit(x_train,y_train)

#define y_pred to make the prediction
y_pred = nb.predict(x_test)

"""## **b- use the classification report to calculate percision, recall and F1 score**

A Classification report is used to measure the quality of predictions from a classification algorithm. How many predictions are True and how many are False. More specifically, True Positives, False Positives, True negatives and False Negatives are used to predict the metrics of a classification report.
"""

from sklearn.metrics import classification_report #to use the function of classification report
print(classification_report(y_train,nb.predict(x_train)))
print(classification_report(y_test,y_pred))

#define the meshgrid function to draw the decision boundary
def make_meshgrid(x, y, h=.02):
    x_min, x_max = x.min() - 1, x.max() + 1
    y_min, y_max = y.min() - 1, y.max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
    return xx, yy

def plot_contours(ax, clf, xx, yy, **params):
    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    out = ax.contourf(xx, yy, Z, **params)
    return out



fig, ax = plt.subplots()
# title for the plots
title = ('Decision boundry of naive bayes training')
# Set-up grid for plotting.
X0, X1 = x_train['proline'], x_train['od280/od315_of_diluted_wines']
xx, yy = make_meshgrid(X0, X1)
#plot the decision boundary on the two features('proline' and 'od280/od315_of_diluted_wines') 
plot_contours(ax, nb.fit(x_train[['proline','od280/od315_of_diluted_wines']], y_train), xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)
ax.scatter(X0, X1, c=y_train, cmap=plt.cm.coolwarm, s=30, edgecolors='k')
ax.set_ylabel('proline')
ax.set_xlabel('od280/od315_of_diluted_wines')
ax.set_xticks(())
ax.set_yticks(())
ax.set_title(title)
ax.legend(y_train.unique(),labels =['2: red', '1: light blue', '0: blue'])
plt.show()

"""plot the decision boundary on test data between 'proline' and 'od280/od315_of_diluted_wines'

"""

fig, ax = plt.subplots()
# title for the plots
title = ('Decision boundry of naive bayes testing')
# Set-up grid for plotting.
X0, X1 = x_test['proline'], x_test['od280/od315_of_diluted_wines']
xx, yy = make_meshgrid(X0, X1)
#plot the decision boundary on the two features('proline' and 'od280/od315_of_diluted_wines') 
plot_contours(ax, nb.fit(x_train[['proline','od280/od315_of_diluted_wines']], y_train), xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)
ax.scatter(X0, X1, c=y_test, cmap=plt.cm.coolwarm, s=30, edgecolors='k')
ax.set_ylabel('proline')
ax.set_xlabel('od280/od315_of_diluted_wines')
ax.set_xticks(())
ax.set_yticks(())
ax.set_title(title)
ax.legend(labels =['2: red', '1: light blue', '0: blue'])
plt.show()

"""#Problem 2: Implement KNN Classifier

## **Load the dataset**
"""

#read the dataset
car = pd.read_csv('/content/car_evaluation.csv')
car.head()

#get some informations about the data
car.info()

#describe the dataset
car.describe()

#counting values in each column
for i in car.columns:
  print(car[i].value_counts())

#perform label encoding 
car['vhigh'] = car['vhigh'].map({'low':0,'med':1,'high':2,'vhigh':3})
car['vhigh.1'] = car['vhigh.1'].map({'low':0,'med':1,'high':2,'vhigh':3})
car['2'] = car['2'].map({'2':0,'3':1,'4':2,'5more':3})
car['2.1'] = car['2.1'].map({'2':0,'4':1,'more':2})
car['small'] = car['small'].map({'small':0,'med':1,'big':2})
car['low'] = car['low'].map({'low':0,'med':1,'high':2})
car['unacc'] = car['unacc'].map({'unacc':0,'acc':1,'good':2,'vgood':3})

#get some information about car dataset
car.info()

#print the head of the data after label encoding
car.head()

"""## **a- split the dataset to training and testing: data preparation step** """

from sklearn.model_selection import train_test_split
x_train, x ,y_train, y = train_test_split(car.drop('unacc',axis = 1) , car['unacc'],train_size = 1000,random_state = 42,stratify=car['unacc'])
x_val,x_test , y_val , y_test = train_test_split(x,y,test_size = 428,random_state = 42,stratify=y)

print(len(x_test))

print(len(x_train))

print(len(x_val))

"""## **b- transform string values into numbers**"""

def percentage(x_train , y_train ,precentage):
  x_train_prc = x_train.iloc[:int(x_train.shape[0]*precentage)]
  y_train_prc = y_train.iloc[:int(y_train.shape[0]*precentage)]
  return x_train_prc , y_train_prc

prc = [.1,.2,.3,.4,.5,.6,.7,.8,.9,1]

"""## **c- plot training set and accuracy score**"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
val_acc = []
test_acc = []

for i in prc:
  x_train_prc , y_train_prc = percentage(x_train , y_train ,i)
  knn = KNeighborsClassifier(n_neighbors=2)
  knn.fit(x_train_prc,y_train_prc)
  y_predval_knn = knn.predict(x_val)
  y_pred_knn = knn.predict(x_test)
  val_acc.append(accuracy_score(y_val,y_predval_knn))
  test_acc.append(accuracy_score(y_test,y_pred_knn))

print("Max Validation Accuracy :- ",max(val_acc))
print("Max test Accuracy :- ",max(test_acc))

plt.plot(prc,val_acc)
plt.plot(prc,test_acc)
plt.title('training precentage vs val and test accuracy')
plt.xlabel('training precentage')
plt.ylabel('accuracy')
plt.legend(labels=['validtion : blue' , 'test :orange'])

"""## **d- accuracy curve on the validation set when K varies from 1 to 10**"""

val_accuracy = []
test_accuracy = []
error_rate = []
for i in range(1,11):
  knn = KNeighborsClassifier(n_neighbors=i)
  knn.fit(x_train,y_train)
  y_pred_val_knn = knn.predict(x_val)
  y_pred_knn_test = knn.predict(x_test)
  val_accuracy.append(accuracy_score(y_val,y_pred_val_knn))
  test_accuracy.append(accuracy_score(y_test,y_pred_knn_test))
  error_rate.append(np.mean(y_pred_knn_test != y_test))
# for i in range
print("Max Validation Accuracy :- ",max(val_accuracy))
print("Max test Accuracy :- ",max(test_accuracy))
print("Min error_rate :- ",min(error_rate))

plt.plot(list(range(1,11)),val_accuracy)
plt.plot(list(range(1,11)),test_accuracy)
plt.title('number of neighbours vs val and test accuracy')
plt.xlabel('K value')
plt.ylabel('accuracy')
plt.legend(labels=['validtion : blue' , 'test :orange'])

"""## **e- Analysis the training time when use different number of training samples.**"""

plt.plot(list(range(1,11)),error_rate)
plt.title('number of neighbours vs error rate')
plt.xlabel('K value')
plt.ylabel('error rate')

# apply 10 % of training and k = 2
import time
x_train_prc , y_train_prc = percentage(x_train , y_train ,0.1)
start_10_t =time.time()
knn_10 = KNeighborsClassifier(n_neighbors=2)
knn_10.fit(x_train_prc,y_train_prc)
end_10_t =time.time()
total_time_t_10 = abs(end_10_t - start_10_t)

start_10_test = time.time()
y_pred = knn_10.predict(x_test)
end_10_test = time.time()
total_time_test_10 = abs(start_10_test - end_10_test)

start_10_test

end_10_test

total_time_test_10

#apply 100% of the whole training set and K = 2
start_100_t =time.time()
knn_100 = KNeighborsClassifier(n_neighbors=2)
knn_100.fit(x_train,y_train)
end_100_t =time.time()
total_time_t_100 = abs(end_100_t - start_100_t)

start_100_test = time.time()
y_pred = knn_100.predict(x_test)
end_100_test = time.time()
total_time_test_100 = abs(start_100_test - end_100_test)

start_100_test

end_100_test

total_time_test_100

#apply 10% of the whole training set and K = 10
x_train_prc_10 , y_train_prc_10 = percentage(x_train , y_train ,0.1)
start_10_t_10 =time.time()
knn_10_10 = KNeighborsClassifier(n_neighbors=10)
knn_10_10.fit(x_train_prc,y_train_prc)
end_10_t_10 =time.time()
total_time_t_10_10 = abs(end_10_t_10 - start_10_t_10)

start_10_test_10 = time.time()
y_pred = knn_10_10.predict(x_test)
end_10_test_10 = time.time()
total_time_test_10_10 = abs(start_10_test_10 - end_10_test_10)

start_10_test_10

end_10_test_10

total_time_test_10_10

#apply 100% of the whole training set and K = 10
start_100_t_10 =time.time()
knn_100_10 = KNeighborsClassifier(n_neighbors=10)
knn_100_10.fit(x_train,y_train)
end_100_t_10 =time.time()
total_time_t_100_10 = abs(end_100_t_10 - start_100_t_10)

start_100_test_10 = time.time()
y_pred = knn_100_10.predict(x_test)
end_100_test_10 = time.time()
total_time_test_100_10 = abs(start_100_test_10 - end_100_test_10)

start_100_test_10

end_100_test_10

total_time_test_100_10

#Plot a bar chart figure to show the prediction time on the testing set
k= ['K=2 10% training','K=2 100% training','K=10 10% training','K=10 100% training']
training_time=[total_time_t_10,total_time_t_100,total_time_t_10_10,total_time_t_100_10]
plt.bar(k,training_time)
plt.title('the effect of trainingsamples and number of K VS time')
plt.xlabel('Kvalue and traing precentage')
plt.ylabel('time')
plt.xticks(rotation = 90)

test_time = [total_time_test_10,total_time_test_100,total_time_test_10_10,total_time_test_100_10]
plt.bar(k,test_time)
plt.title('  criteria VS time')
plt.xlabel('Kvalue and traing precentage')
plt.ylabel('time')
plt.xticks(rotation = 90)

"""#**f- from the experirments on points c, d, e we can say that:**
 

1. when the number of k decreased,  it can leads to an overfitting.
2. When the number of k increased,  it can leads to an underfitting.
3. We must choose the best number of K to prevent overfitting or underfitting.
4. When the number of training data increases, the time will increase because it is a non-parametric model, and it is not limited to that, so it causes better results.

"""